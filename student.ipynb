{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Overview\n","\n","The Terry Stops problem aims to predict the outcome of police stops based on reasonable suspicion using a classification model. The model considers various factors such as presence of weapons, time of day, and possibly gender and race of both the officer and the subject. However, the use of race and gender data raises ethical concerns and the importance of avoiding bias and discrimination must be taken into consideration. The goal of this model is to improve the efficiency and fairness of law enforcement actions, but the agencies must also monitor and address any potential biases.\n","\n","\n","# 1. Business Understanding\n","\n","## 1.1. Problem\n","\n","The Terry Stops presents a business opportunity to improve the efficiency and fairness of law enforcement actions. By developing a predictive model that can assist officers in determining the likelihood of an arrest being made during a Terry Stop, the law enforcement agencies can make informed decisions and potentially reduce the number of false arrests and incidents of police misconduct. However, it is important to approach this problem with caution and transparency, considering the ethical concerns raised by the use of gender and race data. The goal is to provide a tool that can help improve policing, while avoiding biases and discrimination."]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 Aim\n","The aim of this project is to build a classifier that can predict the outcome of a Terry Stop (whether an arrest was made or not) based on reasonable suspicion. This will be done by considering various factors such as the presence of weapons, time of day of the call, and other relevant information. The model will be designed to address the binary classification problem, with the goal of improving the efficiency and fairness of law enforcement actions.\n","\n","\n","## 1.3. 0bjectives\n","To create a predictive model for Terry Stops that accurately predicts the outcome of the stop (arrest made or not)\n","To take into consideration key factors such as the presence of weapons and the time of the call in the model\n","To ensure that the model is ethically sound and avoids any biases or discrimination related to gender and race.\n","\n","# 2. Data Understanding\n","\n","## 2.1 Data Understanding\n","This dataset was provided by the City of Seattle and is managed by the Seattle Police Department. It was created on April 13, 2017 and last updated on February 6, 2023. The dataset contains 54873, rows and 23 columns, each row representing a unique Terry Stop record as reported by the officer conducting the stop. The columns in the dataset include information about the subject of the stop, such as the perceived age group, perceived race, and perceived gender.\n","\n","\n","The dataset also includes information about the officer, such as the officer's gender, race, and year of birth. Additionally, the dataset includes information about the resolution of the stop, any weapons found, the date and time the stop was reported, and information about the underlying Computer Aided Dispatch (CAD) event. The data is updated daily and is licensed under the public domain.\n","\n","# 3. Requirements"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Requirements\n","\n","* Data Preparation -> Loading Libraries -> Loading data -> Descriptive Exploration -> Data Cleaning -> Exploratory Descriptive Analysis (EDA) -> Pre-processing Data\n","\n","* Modelling -> Train test split -> Logistic Regression -> K-Nearest -> Decision Tree -> Logistic Regression -> Random Forest\n","    \n","* Evaluation -> Classification Metrics -> Best Perfoming Model\n","\n","* Conclusion -> Best Model\n","    \n","* Recommendation -> Most imporatnt features"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Data Preparation\n","\n","* Loading Libraries \n","* Loading data \n","* Descriptive Exploration\n","* Data Cleaning \n","* Exploratory Descriptive Analysis (EDA) \n","* Pre-processing Data\n","    * >Update the Stop Resolution column to either be arrested (1) or not arrested (0):\n","    * >Change the date column to datetime so we can work with it. Add in the month as a new column:\n","    * >Group weapons into firearms vs. non-firearms vs. no weapon:\n","    * >Change Officer year of bith to give the officer age:\n","    * >Drop columns that we are not going to need:\n","    * >Converting categorical data to numeric format through label encoder"]},{"cell_type":"markdown","metadata":{},"source":["## 4.1. Loading Libraries\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# import relevant libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2. Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# read the csv file to pandas data frame\n","Tery_df = pd.read_csv(\"data/Terry_Stops.csv\")    \n","\n","# make copy\n","Tery_stops_df = Tery_df.copy(deep=True) \n","\n","# preview the first 3 rows\n","Tery_stops_df.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2.1 Dataset Columns\n","These are the 23 columns, with a concise explanation of the information contained in each column :\n","Subject Age Group: Subject Age Group (10 year increments) as reported by the officer.\n","\n","Subject ID: Key, generated daily, identifying unique subjects in the dataset using a character to character match of first name and last name. \"Null\" values indicate an \"anonymous\" or \"unidentified\" subject. Subjects of a Terry Stop are not required to present identification.\n","\n","GO/SC Num: General Offense or Street Check number, relating the Terry Stop to the parent report. This field may have a one to many relationship in the data.\n","\n","Terry Stop ID: Key identifying unique Terry Stop reports.\n","\n","Stop Resolution: Resolution of the stop as reported by the officer.\n","\n","Weapon Type: Type of weapon, if any, identified during a search or frisk of the subject. Indicates \"None\" if no weapons was found.\n","\n","Officer ID: Key identifying unique officers in the dataset.\n","\n","Officer YOB: Year of birth, as reported by the officer.\n","\n","Officer Gender: Gender of the officer, as reported by the officer.\n","\n","Officer Race: Race of the officer, as reported by the officer.\n","\n","Subject Perceived Race: Perceived race of the subject, as reported by the officer.\n","\n","Subject Perceived Gender: Perceived gender of the subject, as reported by the officer.\n","\n","Reported Date: Date the report was filed in the Records Management System (RMS). Not necessarily the date the stop occurred but generally within 1 day.\n","Reported Time: Time the stop was reported in the Records Management System (RMS). Not the time the stop occurred but generally within 10 hours.\n","\n","Initial Call Type: Initial classification of the call as assigned by 911.\n","\n","Final Call Type: Final classification of the call as assigned by the primary officer closing the event.\n","\n","Call Type: How the call was received by the communication center.\n","\n","Officer Squad: Functional squad assignment (not budget) of the officer as reported by the Data Analytics Platform (DAP).\n","\n","Arrest Flag: Indicator of whether a \"physical arrest\" was made, of the subject, during the Terry Stop. Does not necessarily reflect a report of an arrest in the Records Management System (RMS).\n","\n","Frisk Flag: Indicator of whether a \"frisk\" was conducted, by the officer, of the subject, during the Terry Stop.\n","\n","Precinct: Precinct of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred.\n","\n","Sector: Sector of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred.\n","\n","Beat: Beat of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred."]},{"cell_type":"markdown","metadata":{},"source":["## 4.3. Descriptive Exploration\n","Describing the data set in terms of shape and the data types for all the columns present. Most of the columns are categorical and have the 'object' datatype."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# a function to summarise the data set\n","# check number of categorical and numerical columns\n","def columns_dtypes(df):\n","    print(f\"This dataset has {df.shape[0]} rows and {df.shape[1]} columns\")\n","    print()\n","    num = len(df.select_dtypes(include=np.number).columns)\n","    cat = len(df.select_dtypes(include='object').columns)\n","    print(f\"Numerical columns: {num}\")\n","    print(f\"Categorical columns: {cat}\")\n","    print()\n","    print(\"These are the datatypes of column :\")\n","    return df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# call the function  \n","columns_dtypes(Tery_stops_df)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.4 Data Cleaning\n","\n","Identifying and correcting inaccuracies, inconsistencies, and irrelevant data from a dataset. These were the steps\n","* handling missing values\n","* removing duplicates\n","* correcting data format\n","* transforming variables to make the data ready for modelling and predictions."]},{"cell_type":"markdown","metadata":{},"source":["#### 4.4.1. Missing and Duplicate Values\n","A function to check duplicates and null"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["def check_duplicates_missing(dataframe):\n","    # calculate percentage of missing values\n","    percent_missing = dataframe.isnull().mean().round(4) * 100\n","    count_missing = dataframe.isnull().sum()\n","    # calculate percentage of duplicate rows\n","    percent_duplicates = dataframe.duplicated().mean() * 100\n","    # create result dataframe\n","    result = pd.DataFrame({'Missing Values %': percent_missing, \n","                           'Missing Values Count': count_missing, \n","                           'Duplicate Values %': percent_duplicates})\n","    # find column with most missing values\n","    if percent_missing.max() !=0:\n","        column_most_missing = percent_missing.idxmax()\n","        print(f\"{(column_most_missing).capitalize()} is the column with most null count.\")\n","        print()\n","    else:\n","        print(\"No column with missing values\")\n","    if percent_duplicates.max() !=0:\n","        column_most_duplicates = percent_duplicates.idxmax()\n","        print(\"Column with most duplicates:\",column_most_duplicates)\n","    else:\n","        print(\"No duplicates\")\n","    return result"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
